{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('0520_Getah_lbpafterthreshold.csv') ## read the data\n",
    "\n",
    "data = df['data'].values.tolist() ##take the date from all column\n",
    "\n",
    "## assign the features tu the X[]\n",
    "X = []\n",
    "for each in data:\n",
    "    s = each.split('-')\n",
    "    si = list(map(float, s))\n",
    "    snp = np.array(si)\n",
    "    X.append(snp)\n",
    "\n",
    "## Assign the class label to Y   \n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "z=0\n",
    "C = 5.0 \n",
    "\n",
    "with open(\"SVM_Getah_lbpafterthreshold_0520-1.csv\", \"w\") as fo:\n",
    "\n",
    "    fo.write(\"Linear,RBF,Polynomial\\n\")\n",
    "    score = 0\n",
    "\n",
    "    while (z<10):\n",
    "        ## Split the data, 70:30   \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) \n",
    "\n",
    "        print(\"Train data: {}, Test data: {}\".format(len(X_train), len(X_test)))\n",
    "        \n",
    "        ## Run the C-SVM with Linear Kernel Function\n",
    "        lin_svc = svm.SVC(kernel = 'linear', C=C, verbose=True)  \n",
    "        lin_svc.fit(X_train, y_train) ## train the data\n",
    "        result_lin = round(lin_svc.score(X_test, y_test), 2) ## test and accuracy\n",
    "        \n",
    "        if result_lin >= score:\n",
    "            joblib.dump(lin_svc, 'Model/0520/model-%.2f-linear.pkl' % result_lin)\n",
    "            score = result_lin\n",
    "    \n",
    "        \n",
    "        ## Run the C-SVM with RBF Kernel Function\n",
    "        rbf_svc = svm.SVC(kernel = 'rbf', gamma=0.01, C=C, verbose=True) \n",
    "        rbf_svc.fit(X_train, y_train)\n",
    "        result_rbf = round(rbf_svc.score(X_test, y_test), 2)\n",
    "        \n",
    "        if result_rbf >= score:\n",
    "            joblib.dump(rbf_svc, 'Model/0520/model-%.2f-rbf.pkl' % result_rbf)\n",
    "            score = result_rbf\n",
    "            \n",
    "        ## Run the C-SVM with Polynomial Kernel Function\n",
    "        poly_svc = svm.SVC(kernel = 'poly', C=C,degree=30, verbose=True) \n",
    "        poly_svc.fit(X_train, y_train)\n",
    "        result_poly= round(poly_svc.score(X_test, y_test), 2)\n",
    "    \n",
    "        if result_poly >= score:\n",
    "            joblib.dump(poly_svc, 'Model/0520/model-%.2f-poly.pkl' % result_poly)\n",
    "            score = result_poly\n",
    "            \n",
    "        ## save the result in .csv file\n",
    "        fo.write(\"{},{},{}\\n\".format(result_lin, result_rbf, result_poly))\n",
    "        z=z+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1098_Getah_lbpafterthreshold.csv')\n",
    "\n",
    "# amek data dari column \"data\"\n",
    "data = df['data'].values.tolist()\n",
    "\n",
    "X = []\n",
    "for each in data:\n",
    "    s = each.split('-')\n",
    "    si = list(map(float, s))\n",
    "    snp = np.array(si)\n",
    "    X.append(snp)\n",
    "\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked',)).History will not be written to the database.\n",
      "Training....\n",
      "\n",
      "\n",
      "Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]Train data: 141, Test data: 61\n",
      "[LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTraining....\\n\")\n",
    "##MODELLING KERNEL SVM CLASSIFIER USING SELECTED FEATURES\n",
    "\n",
    "z=0\n",
    "C = 1.0 # SVM regualrization parameter\n",
    "G = 0.01\n",
    "\n",
    "\n",
    "\n",
    "with open(\"SVM_Getah_lbpafterthreshold_1098-1.csv\", \"w\") as fo:\n",
    "\n",
    "    fo.write(\"Linear,RBF,Polynomial\\n\")\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    while (z<10):\n",
    "   \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "        print(\"Train data: {}, Test data: {}\".format(len(X_train), len(X_test)))\n",
    "        lin_svc = svm.SVC(kernel = 'linear', C=C, verbose=True) ### kernel => train(fit func) terus\n",
    "        lin_svc.fit(X_train, y_train)\n",
    "        result_lin = round(lin_svc.score(X_test, y_test), 2)\n",
    "            \n",
    "        if result_lin >= score:\n",
    "            joblib.dump(lin_svc, 'Model/1098/model-%.2f-linear.pkl' % result_lin)\n",
    "            score = result_lin\n",
    "    \n",
    "        rbf_svc = svm.SVC(kernel = 'rbf', gamma=G, C=C, verbose=True) ### kernel => train(fit func) terus\n",
    "        rbf_svc.fit(X_train, y_train)\n",
    "        result_rbf = round(rbf_svc.score(X_test, y_test), 2)\n",
    "    \n",
    "        if result_rbf >= score:\n",
    "            joblib.dump(rbf_svc, 'Model/1098/model-%.2f-rbf.pkl' % result_rbf)\n",
    "            score = result_rbf\n",
    "    \n",
    "        poly_svc = svm.SVC(kernel = 'poly', C=C,degree=30, verbose=True) ### kernel => train(fit func) terus\n",
    "        poly_svc.fit(X_train, y_train)\n",
    "        result_poly= round(poly_svc.score(X_test, y_test), 2)\n",
    "        \n",
    "        if result_poly >= score:\n",
    "            joblib.dump(poly_svc, 'Model/1098/model-%.2f-poly.pkl' % result_poly)\n",
    "            score = result_poly\n",
    "    \n",
    "        fo.write(\"{},{},{}\\n\".format(result_lin, result_rbf, result_poly))\n",
    "        z=z+1\n",
    "    #print (result_r, result_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
